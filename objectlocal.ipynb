{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if we are using TensorFlow 2.4\n",
      "Using TensorFlow version 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, BatchNormalization, Dropout\n",
    "\n",
    "print('Check if we are using TensorFlow 2.4')\n",
    "print('Using TensorFlow version', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = {\n",
    "    0: {'name': 'happy', 'file': '1F642.png'},\n",
    "    1: {'name': 'laughing', 'file': '1F602.png'},\n",
    "    2: {'name': 'skeptical', 'file': '1F928.png'},\n",
    "    3: {'name': 'sad', 'file': '1F630.png'},\n",
    "    4: {'name': 'cool', 'file': '1F60E.png'},\n",
    "    5: {'name': 'whoa', 'file': '1F62F.png'},\n",
    "    6: {'name': 'crying', 'file': '1F62D.png'},\n",
    "    7: {'name': 'puking', 'file': '1F92E.png'},\n",
    "    8: {'name': 'nervous', 'file': '1F62C.png'}\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "for i, (j, e) in enumerate(emojis.items()):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(plt.imread(os.path.join('emojis', e['file'])))\n",
    "    plt.xlabel(e['name'])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_id, values in emojis.items():\n",
    "    png_file = Image.open(os.path.join('emojis', values['file'])).convert('RGBA')\n",
    "    png_file.load()\n",
    "    new_file = Image.new(\"RGB\", png_file.size, (255, 255, 255))\n",
    "    new_file.paste(png_file, mask=png_file.split()[3])\n",
    "    emojis[class_id]['image'] = new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example():\n",
    "  class_id = np.random.randint(0, 9)\n",
    "  image = np.ones((144, 144, 3)) * 255\n",
    "  row = np.random.randint(0, 72)      ## size of the emojis is 72*72 \n",
    "  col = np.random.randint(0, 72)\n",
    "  image[row: row + 72, col: col + 72, :] = np.array(emojis[class_id]['image'])\n",
    "  return image.astype('uint8'), class_id,(row + 10)/144,(col + 10)/144          ## image is taken as an integer 8( buffering size of images\n",
    "                                                                                                  # is added on both sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, class_id, row, col = create_example()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bounding_box(image, gt_coords, pred_coords=[], norm=False):\n",
    "  if norm:\n",
    "    image *= 255.\n",
    "    image = image.astype('uint8')\n",
    "  image = Image.fromarray(image)\n",
    "  draw = ImageDraw.Draw(image)\n",
    "\n",
    "  row, col = gt_coords\n",
    "  row *= 144\n",
    "  col *= 144\n",
    "  draw.rectangle((col, row, col + 52, row + 52), outline = 'green', width = 3)         ## here we removing the buffering size of images \n",
    "                                                                                          #basically we are just cropping the emojis\n",
    "\n",
    "  if len(pred_coords) == 2:\n",
    "    row, col = pred_coords\n",
    "    row *= 144\n",
    "    col *= 144\n",
    "    draw.rectangle((col, row, col + 52, row + 52), outline = 'red', width = 3)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plot_bounding_box(image, gt_coords=[row, col])\n",
    "plt.imshow(image)\n",
    "plt.title(emojis[class_id]['name'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size=16):\n",
    "  while True:\n",
    "    x_batch = np.zeros((batch_size, 144, 144, 3))\n",
    "    y_batch = np.zeros((batch_size, 9))\n",
    "    bbox_batch = np.zeros((batch_size, 2))\n",
    "\n",
    "    for i in range(0, batch_size):\n",
    "      image, class_id, row, col = create_example()\n",
    "      x_batch[i] = image / 255.\n",
    "      y_batch[i, class_id] = 1.0\n",
    "      bbox_batch[i] = np.array([row, col])\n",
    "    yield {'image': x_batch},{'class_out': y_batch, 'box_out':bbox_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example, label = next(data_generator(1))\n",
    "image = example['image'][0]\n",
    "class_id = np.argmax(label['class_out'][0])\n",
    "coords = label['box_out'][0]\n",
    "\n",
    "image = plot_bounding_box(image, coords, norm = True)\n",
    "plt.imshow(image)\n",
    "plt.title(emojis[class_id]['name'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(144, 144, 3), name = 'image')\n",
    "\n",
    "x = input_\n",
    "\n",
    "for i in range(0, 5):\n",
    "  n_filters = 2**(4 + i)\n",
    "  x = Conv2D(n_filters, 3, activation = 'relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = MaxPool2D(2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "\n",
    "class_out = Dense(9, activation = 'softmax', name='class_out')(x)\n",
    "box_out = Dense(2, name = 'box_out')(x)\n",
    "\n",
    "model = tf.keras.models.Model(input_, [class_out, box_out])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iou Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IoU(tf.keras.metrics.Metric):\n",
    "  def __init__(self, **kwargs):\n",
    "    super(IoU, self).__init__(**kwargs)                          ## In this section we are finding the gap between the actual and predicted bounding box#\n",
    "\n",
    "    self.iou = self.add_weight(name='iou', initializer='zeros')\n",
    "    self.total_iou = self.add_weight(name='num_iou', initializer='zeros')\n",
    "    self.num_ex = self.add_weight(name='num_ex', initializer='zeros')\n",
    "  \n",
    "  def update_state(self, y_true, y_pred, sample_weight = None):\n",
    "    def get_box(y):\n",
    "      rows, cols = y[:, 0], y[:,1]\n",
    "      rows, cols = rows * 144, cols * 144\n",
    "      y1, y2 = rows, rows +52\n",
    "      x1, x2 = cols, cols + 52\n",
    "      return x1, y1, x2, y2\n",
    "\n",
    "    def get_area(x1, y1, x2, y2):\n",
    "      return tf.math.abs(x2-x1) * tf.math.abs(y2 - y1)         \n",
    "    \n",
    "    gt_x1, gt_y1, gt_x2, gt_y2 = get_box(y_true)\n",
    "    p_x1, p_y1, p_x2, p_y2 = get_box(y_pred)\n",
    "\n",
    "    \n",
    "\n",
    "    i_x1 = tf.maximum(gt_x1, p_x1)\n",
    "    i_y1 = tf.maximum(gt_y1, p_y1)\n",
    "    i_x2 = tf.minimum(gt_x2, p_x2)\n",
    "    i_y2 = tf.minimum(gt_y2, p_y2)\n",
    "\n",
    "    i_area = get_area(i_x1, i_y1, i_x2, i_y2)                    ## intersection area                                  \n",
    "    u_area = get_area(gt_x1, gt_y1, gt_x2, gt_y2) + get_area(p_x1, p_y1, p_x2, p_y2) - i_area     ## union area\n",
    "    iou = tf.math.divide(i_area, u_area)\n",
    "    self.num_ex.assign_add(1)                                       ## number of examples adding one by one    \n",
    "    self.total_iou.assign_add(tf.reduce_mean(iou))\n",
    "    self.iou = tf.math.divide(self.total_iou, self.num_ex)                    \n",
    "\n",
    "  def result(self):\n",
    "    return self.iou\n",
    "\n",
    "  def reset_state(self):\n",
    "    self.iou = self.add_weight(name='iou', initializer='zeros')\n",
    "    self.total_iou = self.add_weight(name='num_iou', initializer='zeros')\n",
    "    self.num_ex = self.add_weight(name='num_ex', initializer='zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss={\n",
    "        'class_out': 'categorical_crossentropy',    # classification output#\n",
    "        'box_out': 'mse'                            # regression output#\n",
    "    },\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics={\n",
    "        'class_out': 'accuracy',\n",
    "        'box_out':IoU(name='iou')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Callback: ModelTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model(model, test_datagen):\n",
    "  example, label = next(test_datagen)\n",
    "  x = example['image']\n",
    "  y = label['class_out']\n",
    "  box = label['box_out']\n",
    "\n",
    "  pred_y, pred_box = model.predict(x)\n",
    "\n",
    "  pred_coords = pred_box[0]\n",
    "  gt_coords = box[0]\n",
    "  pred_class = np.argmax(pred_y[0])\n",
    "  image = x[0]\n",
    "\n",
    "  gt = emojis[np.argmax(y[0])]['name']\n",
    "  pred_class_name = emojis[pred_class]['name']\n",
    "\n",
    "  image = plot_bounding_box(image, gt_coords, pred_coords, norm=True)\n",
    "  color = 'green' if gt == pred_class_name else 'red'\n",
    "\n",
    "  plt.imshow(image)\n",
    "  plt.xlabel(f'Pred: {pred_class_name}', color=color)\n",
    "  plt.ylabel(f'GT: {gt}',color=color)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "  test_datagen = data_generator(1)\n",
    "\n",
    "  plt.figure(figsize=(16,4))\n",
    "\n",
    "  for i in range(0,6):\n",
    "    plt.subplot(1,6,i+1)\n",
    "    test_model(model, test_datagen)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowTestImages(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs= None):\n",
    "    test(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "  if (epoch + 1) % 5 ==0:                                ## Reduce the learning rate after 5th epoch to 20%\n",
    "    lr *=0.2\n",
    "  return max(lr, 3e-7)\n",
    "  \n",
    "\n",
    "_ = model.fit(\n",
    "    data_generator(),\n",
    "    epochs=50,\n",
    "    steps_per_epoch=500,\n",
    "    callbacks=[\n",
    "               ShowTestImages(),\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='box_out_iou', patience=3, mode='max'),\n",
    "               tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "292297d5f1f836245304c78fa03ec57e8e4aedfb70ce89be415e0fc68df92053"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
